var TYPE = require('../../tokenizer').TYPE;

<<<<<<< HEAD
var COMMENT = TYPE.Comment;
var ASTERISK = 0x002A;        // U+002A ASTERISK (*)
var SOLIDUS = 0x002F;         // U+002F SOLIDUS (/)
=======
var ASTERISK = TYPE.Asterisk;
var SOLIDUS = TYPE.Solidus;
>>>>>>> 99ef3b4711c8dcd2f717e43dd012712d1f333361

// '/*' .* '*/'
module.exports = {
    name: 'Comment',
    structure: {
        value: String
    },
    parse: function() {
        var start = this.scanner.tokenStart;
        var end = this.scanner.tokenEnd;

<<<<<<< HEAD
        this.eat(COMMENT);

=======
>>>>>>> 99ef3b4711c8dcd2f717e43dd012712d1f333361
        if ((end - start + 2) >= 2 &&
            this.scanner.source.charCodeAt(end - 2) === ASTERISK &&
            this.scanner.source.charCodeAt(end - 1) === SOLIDUS) {
            end -= 2;
        }

<<<<<<< HEAD
=======
        this.scanner.next();

>>>>>>> 99ef3b4711c8dcd2f717e43dd012712d1f333361
        return {
            type: 'Comment',
            loc: this.getLocation(start, this.scanner.tokenStart),
            value: this.scanner.source.substring(start + 2, end)
        };
    },
<<<<<<< HEAD
    generate: function(node) {
        this.chunk('/*');
        this.chunk(node.value);
        this.chunk('*/');
=======
    generate: function(processChunk, node) {
        processChunk('/*');
        processChunk(node.value);
        processChunk('*/');
>>>>>>> 99ef3b4711c8dcd2f717e43dd012712d1f333361
    }
};
