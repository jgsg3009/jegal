var TYPE = require('../../tokenizer').TYPE;
<<<<<<< HEAD

=======
>>>>>>> 99ef3b4711c8dcd2f717e43dd012712d1f333361
var LEFTPARENTHESIS = TYPE.LeftParenthesis;
var RIGHTPARENTHESIS = TYPE.RightParenthesis;

module.exports = {
    name: 'Parentheses',
    structure: {
        children: [[]]
    },
    parse: function(readSequence, recognizer) {
        var start = this.scanner.tokenStart;
        var children = null;

<<<<<<< HEAD
        this.eat(LEFTPARENTHESIS);

        children = readSequence.call(this, recognizer);

        if (!this.scanner.eof) {
            this.eat(RIGHTPARENTHESIS);
        }
=======
        this.scanner.eat(LEFTPARENTHESIS);
        children = readSequence.call(this, recognizer);
        this.scanner.eat(RIGHTPARENTHESIS);
>>>>>>> 99ef3b4711c8dcd2f717e43dd012712d1f333361

        return {
            type: 'Parentheses',
            loc: this.getLocation(start, this.scanner.tokenStart),
            children: children
        };
    },
<<<<<<< HEAD
    generate: function(node) {
        this.chunk('(');
        this.children(node);
        this.chunk(')');
=======
    generate: function(processChunk, node) {
        processChunk('(');
        this.each(processChunk, node);
        processChunk(')');
>>>>>>> 99ef3b4711c8dcd2f717e43dd012712d1f333361
    }
};
